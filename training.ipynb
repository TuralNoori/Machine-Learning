{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mina imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import fetch_openml\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST-datasetet från OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "X = mnist.data.to_numpy()\n",
    "y = mnist.target.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisera datan och uppdelning är 70% träning och 15% validering samt 15 % test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapar och tränar en Random Forest modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for Random Forest model: 0.9668571428571429\n",
      "Test accuracy for Random Forest model: 0.9667619047619047\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_val_predictions = rf_model.predict(X_val)\n",
    "rf_val_accuracy = accuracy_score(y_val, rf_val_predictions)\n",
    "print(f\"Validation accuracy for Random Forest model: {rf_val_accuracy}\")\n",
    "\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_predictions)\n",
    "print(f\"Test accuracy for Random Forest model: {rf_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapar och tränar en Ligistic Regression modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for Logistic Regression model: 0.9245714285714286\n",
      "Test accuracy for Logistic Regression model: 0.9194285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=100, solver='lbfgs', multi_class='multinomial', random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_val_predictions = lr_model.predict(X_val)\n",
    "lr_val_accuracy = accuracy_score(y_val, lr_val_predictions)\n",
    "print(f\"Validation accuracy for Logistic Regression model: {lr_val_accuracy}\")\n",
    "\n",
    "lr_test_predictions = lr_model.predict(X_test)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_predictions)\n",
    "print(f\"Test accuracy for Logistic Regression model: {lr_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapar och tränar en MLP modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for MLP model: 0.9795238095238096\n",
      "Test accuracy for MLP model: 0.9798095238095238\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam', max_iter=300, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "mlp_val_predictions = mlp_model.predict(X_val)\n",
    "mlp_val_accuracy = accuracy_score(y_val, mlp_val_predictions)\n",
    "print(f\"Validation accuracy for MLP model: {mlp_val_accuracy}\")\n",
    "\n",
    "mlp_test_predictions = mlp_model.predict(X_test)\n",
    "mlp_test_accuracy = accuracy_score(y_test, mlp_test_predictions)\n",
    "print(f\"Test accuracy for MLP model: {mlp_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapar och tränar en XGBoost modell som i sin tur fick jag omvandla data till DMatrix format som XGBoost förväntar sig samt skapar standardparametrar för modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for XGBoost model: 0.9414285714285714\n",
      "Test accuracy for XGBoost model: 0.9431428571428572\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 10,\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'eval_metric': 'merror'\n",
    "}\n",
    "\n",
    "bst_model = xgb.train(params, dtrain, num_boost_round=10)\n",
    "\n",
    "xgb_val_predictions = bst_model.predict(dval)\n",
    "xgb_val_accuracy = accuracy_score(y_val, xgb_val_predictions)\n",
    "print(f\"Validation accuracy for XGBoost model: {xgb_val_accuracy}\")\n",
    "\n",
    "xgb_test_predictions = bst_model.predict(dtest)\n",
    "xgb_test_accuracy = accuracy_score(y_test, xgb_test_predictions)\n",
    "print(f\"Test accuracy for XGBoost model: {xgb_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammanfattning av resultaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison (Validation and Test Accuracy):\n",
      "Random Forest (Validation): 0.9669\n",
      "Logistic Regression (Validation): 0.9246\n",
      "MLP (Validation): 0.9795\n",
      "XGBoost (Validation): 0.9414\n",
      "Random Forest (Test): 0.9668\n",
      "Logistic Regression (Test): 0.9194\n",
      "MLP (Test): 0.9798\n",
      "XGBoost (Test): 0.9431\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Random Forest (Validation)': rf_val_accuracy,\n",
    "    'Logistic Regression (Validation)': lr_val_accuracy,\n",
    "    'MLP (Validation)': mlp_val_accuracy,\n",
    "    'XGBoost (Validation)': xgb_val_accuracy,\n",
    "    'Random Forest (Test)': rf_test_accuracy,\n",
    "    'Logistic Regression (Test)': lr_test_accuracy,\n",
    "    'MLP (Test)': mlp_test_accuracy,\n",
    "    'XGBoost (Test)': xgb_test_accuracy\n",
    "}\n",
    "\n",
    "print(\"\\nModel Comparison (Validation and Test Accuracy):\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Här bestämmer koden vilken modell som presterat bäst baserat på accuracy (testnoggrannhet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: MLP with a test accuracy of 0.9798\n"
     ]
    }
   ],
   "source": [
    "best_model_name = ''\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "if rf_test_accuracy > best_accuracy:\n",
    "    best_accuracy = rf_test_accuracy\n",
    "    best_model = rf_model\n",
    "    best_model_name = 'Random Forest'\n",
    "if lr_test_accuracy > best_accuracy:\n",
    "    best_accuracy = lr_test_accuracy\n",
    "    best_model = lr_model\n",
    "    best_model_name = 'Logistic Regression'\n",
    "if mlp_test_accuracy > best_accuracy:\n",
    "    best_accuracy = mlp_test_accuracy\n",
    "    best_model = mlp_model\n",
    "    best_model_name = 'MLP'\n",
    "if xgb_test_accuracy > best_accuracy:\n",
    "    best_accuracy = xgb_test_accuracy\n",
    "    best_model = bst_model\n",
    "    best_model_name = 'XGBoost'\n",
    "\n",
    "print(f\"The best model is: {best_model_name} with a test accuracy of {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparar modellen samt testar att ladda ned den efter sparning och med hjälp av en dummy-input testar den för att se om den fungerar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction: [5]\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_model, 'best_model1.pkl')\n",
    "\n",
    "model = joblib.load('best_model1.pkl')\n",
    "\n",
    "dummy_input = np.zeros((1, 784), dtype=np.float64)\n",
    "try:\n",
    "    print(\"Test prediction:\", model.predict(dummy_input))\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
